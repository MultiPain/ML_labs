{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U portalocker>=2.0.0"
      ],
      "metadata": {
        "id": "LOf0TrYgfhvW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PU39iVK9e8Vp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import os\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Z2Y_j2x0v4O_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pipe, test_pipe = torchtext.datasets.AG_NEWS()\n",
        "\n",
        "train_iter = IterableWrapper(train_pipe)\n",
        "test_iter = IterableWrapper(test_pipe)"
      ],
      "metadata": {
        "id": "xS0fZL3Dovh3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_wrapp):\n",
        "  data_iterator = iter(data_wrapp)\n",
        "  for _, text in data_iterator:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])"
      ],
      "metadata": {
        "id": "YQcIR-1Mp-sQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "7C3mc83_yhn5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['here', 'is', 'an', 'example'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lIUVFtbq2fD",
        "outputId": "0e5d0f0e-dbe8-4c79-f7f8-d675871d2142"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 30, 5297]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "metadata": {
        "id": "ON79ssHZvsWP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline('here is the an example')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d5tOVM5vuUr",
        "outputId": "534db35b-9dd9-43bd-919e-59dcbb37b912"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 2, 30, 5297]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline('10')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyhwCwGQvvu8",
        "outputId": "c4186ebe-c474-4585-8fe1-0a9ea8f00de7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "jPVQcvQ8v_ro"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "id": "4ai6OmOJwNmS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "metadata": {
        "id": "eRoFMnulwPu7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count\n"
      ],
      "metadata": {
        "id": "0bQiGL4WwVdL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUB4wofPwYak",
        "outputId": "48829983-c139-4386-d574-d3753e5621f8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1782 batches | accuracy    0.686\n",
            "| epoch   1 |  1000/ 1782 batches | accuracy    0.855\n",
            "| epoch   1 |  1500/ 1782 batches | accuracy    0.879\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 45.57s | valid accuracy    0.876 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1782 batches | accuracy    0.896\n",
            "| epoch   2 |  1000/ 1782 batches | accuracy    0.902\n",
            "| epoch   2 |  1500/ 1782 batches | accuracy    0.901\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 36.52s | valid accuracy    0.896 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1782 batches | accuracy    0.914\n",
            "| epoch   3 |  1000/ 1782 batches | accuracy    0.914\n",
            "| epoch   3 |  1500/ 1782 batches | accuracy    0.915\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 38.95s | valid accuracy    0.902 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1782 batches | accuracy    0.925\n",
            "| epoch   4 |  1000/ 1782 batches | accuracy    0.925\n",
            "| epoch   4 |  1500/ 1782 batches | accuracy    0.921\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 37.39s | valid accuracy    0.909 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1782 batches | accuracy    0.932\n",
            "| epoch   5 |  1000/ 1782 batches | accuracy    0.926\n",
            "| epoch   5 |  1500/ 1782 batches | accuracy    0.931\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 37.13s | valid accuracy    0.913 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1782 batches | accuracy    0.937\n",
            "| epoch   6 |  1000/ 1782 batches | accuracy    0.934\n",
            "| epoch   6 |  1500/ 1782 batches | accuracy    0.932\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 36.81s | valid accuracy    0.902 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1782 batches | accuracy    0.946\n",
            "| epoch   7 |  1000/ 1782 batches | accuracy    0.949\n",
            "| epoch   7 |  1500/ 1782 batches | accuracy    0.947\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 35.93s | valid accuracy    0.917 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1782 batches | accuracy    0.949\n",
            "| epoch   8 |  1000/ 1782 batches | accuracy    0.948\n",
            "| epoch   8 |  1500/ 1782 batches | accuracy    0.948\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 33.34s | valid accuracy    0.915 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1782 batches | accuracy    0.951\n",
            "| epoch   9 |  1000/ 1782 batches | accuracy    0.950\n",
            "| epoch   9 |  1500/ 1782 batches | accuracy    0.950\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 32.76s | valid accuracy    0.913 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1782 batches | accuracy    0.949\n",
            "| epoch  10 |  1000/ 1782 batches | accuracy    0.950\n",
            "| epoch  10 |  1500/ 1782 batches | accuracy    0.952\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 35.01s | valid accuracy    0.914 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.3f}\".format(accu_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnk20n1bwpbb",
        "outputId": "639be10b-1771-40eb-a51d-7373505af17a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
        "\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_sport_news = \"January 2024 has been a tale of two transfers for Tottenham Hotspur. If the loan signing of RB Leipzig’s Timo Werner was simple, clean, discrete, and almost entirely wrapped up by the time it was first reported last weekend, the arrival of Radu Dragusin from Genoa has been quite the opposite.\\\n",
        "Even at this early stage in the winter window, the Dragusin move turned into a very public saga — the type that clubs prefer to avoid.\\\n",
        "Having been in pole position to sign the Romanian centre-back last week, Tottenham were caught off-guard by Bayern Munich’s late attempt to hijack the deal. There were moments on Tuesday when it looked as if Bayern — who offered both Genoa and Dragusin more money — would get the 21-year-old defender.\\\n",
        "But Tottenham were desperate not to miss out on a player they had prioritised for this window. And it took chairman Daniel Levy and technical director Johan Lange working until 3am on Wednesday, making every possible effort to persuade the player to come to Spurs and get the move over the line.\\\n",
        "Dragusin himself stayed up all night to weigh up the final decision of where to go, according to his adviser Florian Manea. It was only when Dragusin and Manea were on their way to the airport a few hours later that they finally made their minds up and told Bayern they would not be coming to Bavaria.\"\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" % ag_news_label[predict(ex_text_str, text_pipeline)])\n",
        "print(\"This is a %s news\" % ag_news_label[predict(ex_sport_news, text_pipeline)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCUxEhHGwtj_",
        "outputId": "730860bb-56e0-4a20-f381-3685400789e2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Sports news\n",
            "This is a Sports news\n"
          ]
        }
      ]
    }
  ]
}